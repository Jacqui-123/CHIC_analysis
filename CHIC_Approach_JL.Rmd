---
##RHBN CHIC Analysis
---

The functions and suggested workflow to tidy WSC data and analyze CHIC variables for the RHBN analysis. 

Developed by Jacqui Levy, Sept 2024. 

```{r}
library(IHA)
library(tidyverse)
library(tidyhydat)
library(zoo)
library(lubridate)
library(ggplot2)
library(dataRetrieval)

source("scripts/add_water_year.R")
source("scripts/Eflows_WSC_functions.R")
```

##Get RHBN stations 
This can be used when the full data set is ready, as the full dataset is too much data to be used on each of the functions. Can also just increment by 1:300 stations etc, as well - it doesn't have to be by EcoRegion, but this can be nice for graphing and exploring later on. 

```{r}
#from govt canada RHBN list: https://www.canada.ca/en/environment-climate-change/services/water-overview/quantity/monitoring/survey/data-products-services/reference-hydrometric-basin-network.html

stns <- read.csv("data/RHBN_Metadata.csv" ) %>% filter(DATA_TYPE == "Q") 

stns <- stns %>%
  mutate(STATION_NUMBER = toupper(STATION_NUMBER)) %>%
  distinct(STATION_NUMBER, .keep_all = TRUE) %>%
  arrange()

```


```{r}

#put station numbers into a list, by ecoregion

stn_num_eco <- stns %>% 
  mutate(Ecoregion = ifelse(Ecoregion == '', "No Ecoregion", Ecoregion)) %>%
  distinct(STATION_NUMBER, .keep_all = TRUE) %>%
  group_by(Ecoregion) %>%
  summarise(STATION_NUMBER = list(STATION_NUMBER))

#loop through this and get several vectors of station ids

ecoreglist <- list()
for (i in unique(stn_num_eco$Ecoregion)) {
    
    df_subset <- stn_num_eco[stn_num_eco$Ecoregion == i,]
    vec <-  as.vector(unlist(df_subset$STATION_NUMBER))
    names(vec) <- i
    ecoreglist[[i]] <- vec
}

```


```{r}

#Use tidyhydat database to get daily flows for all ecoregions and put all dataframes in a list - probably won't use now that the dataset is being tidied and delivered via excel.
eastern_temp_forests <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Eastern Temperate Forests`)
great_plains <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Great Plains`)
hudson_plains <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Hudson Plains`)
w_coast_forests <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Marine West Coast Forests`)
no_ecoregion <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`No Ecoregion`)
n_american_deserts <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`North American Deserts`)
northern_forests <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Northern Forests`)
nw_forested_mtns <- tidyhydat::hy_daily_flows(station_number = ecoreglist$`Northwest Forested Mountains`)
taiga <- tidyhydat::hy_daily_flows(station_number = ecoreglist$Taiga)
tundra <- tidyhydat::hy_daily_flows(station_number = ecoreglist$Tundra)

df_all <- bind_rows(eastern_temp_forests, great_plains, hudson_plains, w_coast_forests, no_ecoregion, n_american_deserts, northern_forests, nw_forested_mtns, taiga, tundra )

rm(ecoreglist, stn_num_eco, df_subset)

rm(eastern_temp_forests, great_plains, hudson_plains, w_coast_forests, no_ecoregion, n_american_deserts, northern_forests, nw_forested_mtns, taiga, tundra )

```


#Test stations from HYDAT for development purposes/this analysis
```{r}

stn_07DA001 <- tidyhydat::hy_daily_flows(station_number = "07DA001") 
stn_07AA001 <- tidyhydat::hy_daily_flows(station_number = "07AA001") 
stns <- tidyhydat::hy_daily_flows(station_number = c("07DA001", "07DD002"))

hy_stations(station_number = "07DA001")

```

Convert to runoff 

```{r}

df_drainage <- tidyhydat::hy_stations(station_number = c("07DA001", "07DD002")) %>% 
  select(STATION_NUMBER, DRAINAGE_AREA_GROSS)

merged <- merge(stns, df_drainage)

df_runoff <- merged %>%
  mutate(runoff = (Value/(DRAINAGE_AREA_GROSS*1000*1000)*1000*86400) ) %>%
  select(-c(Value, DRAINAGE_AREA_GROSS)) %>%
  dplyr::rename(Value = runoff) 

rm(merged)
```

#Data preparation 

1) Get a complete set of years for 1970-2020, for example
(by year, not water year)

complete() is used to make sure there is a complete set of days for each year. In HYDAT if there is no data there is not a record for that day. It's useful to have a complete set of days for each year to be able to tell later on how many days or years are missing. Other functions in this workbook rely on having a complete set of years, even for seasonal data, so don't skip this step - it's better to expand all years and then delete months to get seasonal data later on. Examples of using seasonal data are later on.

-note that when complete is used with seq.Date, it will account for and add leap years
```{r}

#function to filter and get a complete set of years between selected dates. Change the dates and run the function again to save it in the environment with the desired dates.


tidying <- function(df){
  tidied <- df %>%
  group_by(STATION_NUMBER) %>%
  tidyr::complete(Date = seq.Date(as.Date("1969-08-01"), as.Date("2020-07-31"), by="day")) %>%
  mutate(Date = as.Date(Date)) %>%
  filter(Date >= "1969-08-01" & Date <= "2021-07-31") %>%
    ungroup()
  
  counts <- tidied %>%
   mutate(Year = year(Date)) %>%
  filter(Year > 1969 & Year < 2020) %>%
  group_by(STATION_NUMBER, Year) %>%
  dplyr::summarize(count = n()) %>%
  filter(count < 365) 
  
 counts_yr <- tidied %>%
   mutate(Year = year(Date)) %>%
  filter(Year > 1969 & Year < 2020) %>%
  select(-c(Date, Value, Symbol, Parameter)) %>%
  distinct() %>%
  mutate(counts = n_distinct(Year)) %>%
  filter(counts < 50) 
  
  if (nrow(counts) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 365 or 366 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$Year, 
                       ", Values: ", counts$count, collapse = "\n")) 
  }else {"all stations have 365 or 366 days per calendar Year"}
  
 
 if (nrow(counts_yr) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 50 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$Year, 
                       ", Values: ", counts$count, collapse = "\n")) 
  } else {"all stations have 50 years"}
  
    rm(counts, counts_yr)

  return(tidied)

}

#use the function above to tidy data and get a complete set of days for each year. If there are errors or warnings then remove those years or widen the filter(Year > x & Year < x) 

df_tidied <- tidying(df_runoff)
rm(df_runoff)

```


2) Get the water year
 and make sure there are 365-366 set of days for each WY and 50 water years  

```{r}


df_wy <- add_water_year(df_tidied, 10)


  counts <- df_wy %>%
  filter(waterYear > 1969 & waterYear < 2021) %>%
  group_by(STATION_NUMBER, waterYear) %>%
  summarize(count = n()) %>%
  filter(count < 365) 
  
  
 counts_yr <- df_wy %>%
   mutate(Year = year(Date)) %>%
  filter(Year > 1969 & Year < 2020) %>%
  select(-c(Date, Value, Symbol, Parameter)) %>%
  distinct() %>%
  mutate(counts = n_distinct(Year)) %>%
  filter(counts < 50) 
  
  if (nrow(counts) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 365 or 366 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$waterYear, 
                       ", Values: ", counts$count, collapse = "\n")) 
  } else {"all stations have 365 or 366 days per chosen Water Year"}
 
 
 if (nrow(counts_yr) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 50 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$Year, 
                       ", Values: ", counts$count, collapse = "\n")) 
  } else {"all stations have 50 years"}
  
    rm(counts, counts_yr)

#if there are warnings, then filter out those years and re-run code above

#for example:
df_wy <- df_wy %>%
filter(!waterYear %in% c(1969, 2021))
```

3) Get the day of the year next, ie a sequence of 1-365 or 366 for each group of STATION_NUMBER, waterYear

```{r}

df_doy <- calc_day_of_wyear(df_wy)

#if there are errors filter out offending years and re-run:
df_doy <- df_doy %>% filter(!waterYear %in% c(1969, 2021))

check_max <- df_doy %>%
  mutate(max = max(day_of_year)) %>%
  filter(max > 366) %>%
  distinct()

if(nrow(check_max) > 0){
            warning("There are days of the year that number more than 366, check the day of the year function")
}  else {"The days in the year are 365 or 366 days"}

rm(check_max) 


```

4) Get the weeks 1:52 for each year  

```{r}


df_ready <- calc_weeks(df_doy)

#checks
check_max <- df_ready %>%
  mutate(max = max(weeks)) %>%
  filter(max > 52) 

if(nrow(check_max) > 0){
            warning("There are more than 52 weeks in the year, check the week function or data")
} else {"all years have 52 weeks in a year"}

```
#Address missing data

There are a series of helper functions located in "Eflows_WSC_functions.R" that delete weeks, months, or years with a certain amount of missing data (ie "NA" for Value)

```{r}

#Example usage:
rem_missing_months(data, days = 3) #removes months with 3 or more days of missing data (not contiguous)
rem_missing_wks(data, days = 4) #removes weeks with 4 or more days of missing data (not contiguous)
rem_missing_years(data, days = 3) #removes months with missing days >3 and then removes years with any number of missing months. 
calc_rle(data, days = 3) #removes a full year if there are 3 days or more of contiguous missing data
```

Missing data for min-max variables:

For the 1,3,7,15,30,90, etc day magnitude maximums and minimums, the plan is to delete a year if it has 3 or more days of missing data in a row (ie NA's for Value column). The calc_rle function (rle = "run length encoding"), calculates how many days in a row there are of missing data, and then deletes years with > x days of NAs in a row. 

To deal with missing data for the min-max variables, do the following:

```{r}

#delete year if there are 3 days or more contiguous NAs for seasonal/annual data

df_seas <- df_ready #%>%
  #filter(month(Date) %in% c(3,4,5,6,7,8,9,10)) #add this to get seasonal data, and save as a different dataframe than the annual dataframe

lst_stns <- split(df_ready, df_ready$STATION_NUMBER)
lst_stns <- lapply(lst_stns, function(x) calc_rle(x, days = 3))
del_yr_nas <- bind_rows(lst_stns, .id = "STATION_NUMBER")

```
To address missing data for the annual mean/medians:
Delete months that have 3 days or more missing a month, and only calculate annual means if all 12 months are available

```{r}

#delete week if there are 3 days or more contiguous NAs

df_seas <- df_doy #%>%
  #filter(month(Date) %in% c(3,4,5,6,7,8,9,10)) #add this to get seasonal data, and save as a different dataframe

lst_stns <- split(df_seas, df_seas$STATION_NUMBER)
lst_stns <- lapply(lst_stns, function(x) rem_missing_years(x, days = 3))
del_yr_nas <- bind_rows(lst_stns, .id = "STATION_NUMBER")


```

To deal with missing data for the weekly means:
Delete week if there is 1 day or less missing for that week

```{r}

#delete week if there are 1 days or more NAs

df_seas <- df_doy #%>%
  #filter(month(Date) %in% c(3,4,5,6,7,8,9,10)) #add this to get seasonal data, and save as a different dataframe

lst_stns <- split(df_seas, df_seas$STATION_NUMBER)
lst_stns <- lapply(lst_stns, function(x) rem_missing_wks(x, days = 1))
del_yr_nas <- bind_rows(lst_stns, .id = "STATION_NUMBER")

```

Missing data for other annual variables: rise rate, fall rate, reversals, #zero flow days, # min pulses, #max pulses, 

If there are 3 days or less missing per month, delete that month. 

```{r}

#delete mnth

df_seas <- df_doy #%>%
  #filter(month(Date) %in% c(3,4,5,6,7,8,9,10)) #add this to get seasonal data, and save as a different dataframe

lst_stns <- split(df_seas, df_seas$STATION_NUMBER)
lst_stns <- lapply(lst_stns, function(x) rem_missing_months(x, days = 3))
del_yr_nas <- bind_rows(lst_stns, .id = "STATION_NUMBER")


```


#Annual variables - calculations 

-note that these work with the water year starting in any month, as long as you have a "waterYear" column (use "add_water_year(data, month = x)" to get a water year that starts in the desired month) 
-assume that data has been removed according to rules above 

```{r}
#for two or more stations at a time:

lst_stns <- split(df_ready, df_ready$STATION_NUMBER )

#apply desired function to all dfs in the list
lst_stns <- lapply(lst_stns, calc_mn_md_week) ##replace function here with: calc_mn_md_month, calc_mn_md_annual, calc_mn_md_seasonal

#Combine all outputs into one df (unnlist the dfs)
output <- bind_rows(lst_stns, .id = "STATION_NUMBER")
View(output)

```


#Spring Freshet Initiation
Date and Magnitude

Extract if 3 days or less contiguous of misisng data and 10% or less total missing during the freshet period. Can do linear interpolation to infill missing data, if any data is missing- waiting on Daniel for this. Daniel will provide percentile (right now it's for 10%) and how many days in a row can be interpolated

Start over with data preparation with the raw dataset, as in order for the functions to work we need the water year to start on March 1 and end on Oct 31, and then need the day of the year to start from Jan 1. 

First, get the water year for freshet and make sure there are 365-366 set of days for each WY and 50 water years  

```{r}


df_wy <- df_tidied %>%
  mutate(waterYear = year(Date)) 


  counts <- df_wy %>%
  filter(waterYear > 1969 & waterYear < 2020) %>%
  group_by(STATION_NUMBER, waterYear) %>%
  summarize(count = n()) %>%
  filter(count < 365) 
  
  
 counts_yr <- df_wy %>%
   mutate(Year = year(Date)) %>%
  filter(Year > 1969 & Year < 2020) %>%
  select(-c(Date, Value, Symbol, Parameter)) %>%
  distinct() %>%
  mutate(counts = n_distinct(Year)) %>%
  filter(counts < 50) 
  
  if (nrow(counts) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 365 or 366 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$waterYear, 
                       ", Values: ", counts$count, collapse = "\n")) 
  } else {"all stations have 365 or 366 days per chosen Water Year"}
 
 
 if (nrow(counts_yr) > 0) {
    warning("There are STATION_NUMBER, Year groups that do not have 50 values:\n",
            paste0("STATION_NUMBER: ", counts$STATION_NUMBER, 
                       ", waterYear: ", counts$Year, 
                       ", Values: ", counts$count, collapse = "\n")) 
  } else {"all stations have 50 years"}
  
    rm(counts, counts_yr)


```

Get the day of the year next

```{r}


df_doy <- calc_day_of_wyear(df_wy)

df_doy <- df_doy %>% filter(waterYear < 2020 & waterYear > 1969)

check_max <- df_doy %>%
  mutate(max = max(day_of_year)) %>%
  filter(max > 366) %>%
  distinct()

if(nrow(check_max) > 0){
            warning("There are days of the year that number more than 366, check the day of the year function")
}  else {"The days in the year are 365 or 366 days"}

rm(check_max) 

```


```{r}

#delete year if there are 3 days or more contiguous NAs for seasonal data

df_seas <- df_doy %>%
  filter(month(Date) %in% c(3,4,5,6,7,8,9,10)) 

lst_stns <- split(df_seas, df_seas$STATION_NUMBER)
lst_stns <- lapply(lst_stns, function(x) calc_rle(x, days = 3))#calc_rle deleted missing data >3 days contiguous
del_yr_nas <- bind_rows(lst_stns, .id = "STATION_NUMBER")


#make sure that there are oct-march for all stn, wyears
check_mnths <- del_yr_nas %>% 
    mutate(month = month(Date)) %>%
  group_by(STATION_NUMBER, waterYear) %>%
  select(STATION_NUMBER, waterYear, month) %>%
  distinct() %>%
  summarise(num_months = n()) %>%
  filter(num_months < 8) %>% ungroup()

check_days <- del_yr_nas %>%
  mutate(month = month(Date)) %>%
  group_by(STATION_NUMBER, waterYear, month) %>%
  summarise(num_days =  n()) %>%
  filter(num_days < 30) 


  if (nrow(check_mnths) > 0) {
    warning("There are STATION_NUMBER, Year groups that have less than 8 months: \n",
            paste0("STATION_NUMBER: ", check_mnths$STATION_NUMBER, 
                       ", waterYear: ", check_mnths$Year, 
                        collapse = "\n")) 
  } else {"all stations have 8 days per water year"}


  if (nrow(check_days) > 0) {
    warning("There are STATION_NUMBER, Year groups that have less than 30 days in a month: \n",
            paste0("STATION_NUMBER: ", check_mnths$STATION_NUMBER, 
                       ", waterYear: ", check_mnths$Year, 
                        collapse = "\n")) 
  } else {"all stations have at least 30 days per month for each water year"}

```


get percentiles of runoff from March 1 - Oct 31

```{r}

freshet_percentile <- function(data){
  
  df <- data %>%
  group_by(STATION_NUMBER, waterYear) %>%
  mutate(sum_runoff = sum(Value)) %>%
  mutate(runoff_10 = sum_runoff*.1) %>%
  mutate(cuml_sum = cumsum(Value)) 
  
  result <- df %>%group_by(STATION_NUMBER, waterYear) %>%


  do({
    df_subset <- .
    perc_cumsum <- df_subset[which.min(abs(df_subset$runoff_10-df_subset$cuml_sum)),] 
    perc_cumsum <- data.frame(perc_cumsum)
  })
  return(result)
}

freshet <- freshet_percentile(del_yr_nas)

```


```{r}

mcmurray <- read.csv("data/Athabasa River Ft McMurray_Spring Freshet_all methods_Jacqui.csv") %>% rename("waterYear" = "Year", "Manual_DOY_McMurray" = "Manual.Spring.Freshet.Day.of.Year") %>% select(STATION_NUMBER, waterYear, Manual_DOY_McMurray)

richards <- read.csv("data/Richardson_Spring Freshet_Manual_Burns methods_Jacqui.csv") %>% rename("waterYear" = "Year", "Manual_DOY_Richardson" = "Manual.Spring.Freshet.Day.of.Year") %>% select(STATION_NUMBER, waterYear, Manual_DOY_Richardson)

df1 <- left_join(freshet, richards, by = c("STATION_NUMBER", "waterYear"))
merged <- left_join(df1, mcmurray, by = c("STATION_NUMBER", "waterYear") )

pivoted <- merged %>%
  select(-c(Date, Parameter, Symbol, Value, sum_runoff, cuml_sum, runoff_10)) %>%
  pivot_longer(cols = c("day_of_year", "Manual_DOY_Richardson", "Manual_DOY_McMurray" ), names_to = "Doy_type", values_to = "Doy_values" )  %>%
  mutate(Doy_type = 
           case_when(Doy_type == 'day_of_year' ~ paste(Doy_type,STATION_NUMBER, sep = '_'), TRUE ~ Doy_type) ) %>%
  ungroup() %>% select(-c(STATION_NUMBER)) %>% distinct() %>%
  na.omit()

#write.csv(pivoted, "freshet_percentiles.csv")

```

#Center of Mass 

Magnitude and Date

If March to October available above, then calculate the seasonal center of mass, even if have year-round data available.

Do only if 3 days or less contiguous missing per time period and must be 10% or less total data missing during March-Oct.

Sum up the runoff for the year from March 1, then find the median, and then find the date at which the median occurs. ie. if value is 500, find when just passes 50th percentile, use that. Water resources engineering variables


```{r}

#calculate the center of mass, ie when cumulative runoff just passes the 50th percentile
#assume missing data has been removed

center_mass_df <- center_of_mass(df_ready)

```

#Max/min for: 3, 7, 15, 30, and 90 days

(in progress)

Usually, these variables are calculated using the IHA library, as demonstrated below. However, the CHIC approach requires not just the magnitude of the min/max but also the date at which this occurs. This is in progress, but here is the IHA approach with will give the magnitudes: 


-note that calc_IHA is currently set to water year, you can change year = "calendar" in the 'Eflows_IHA_functions.R' functions script.

-The IHA functions only work on a standard calendar year or a water year of Oct-Sept, you can't change the start month for the water year for the IHA calculations. Instead see the Annual variables section below to calculate annual variables if the water year starts in a different month than Oct. 

-The data input for the IHA functions must be in day-month-year, and there should not be NAs

```{r}

#change date format to day-month-year as is required for IHA functions 
stns_daymonthyear <- df_ready %>%
  mutate(Date = format(Date,"%d-%m-%Y")) %>%
  group_by(STATION_NUMBER) %>%
  fill(Value, .direction = 'downup') #fill missing values going down then up (ie if at start of df) 


#you may not need to run fill() if you used one of the functions to remove months/years etc, but often the IHA functions will throw an error if there are any missing days so it's good to have just in case. Just beware of running fill() if you have a lot of missing data, as this will just fill in all days, linearly/indiscriminately, no matter how many days of missing data there are. Ie if there are 100 days of missing data it will interpolate or fill all 100 of those days from the last known value. It's suggested to run one of the missing data functions to remove data with too many missing values before interpolating using fill()

```


Calculate IHA variables by station number and combine into a single dataframe:
```{r}

#split-apply-combine process to split by station number and apply the IHA functions across all station numbers and water years. 

lst_stns <- split(stns_daymonthyear, stns_daymonthyear$STATION_NUMBER )

#apply calc_IHA function to all dfs in the list
lst_stns_IHA <- lapply(lst_stns, calc_IHA)

#Combine all IHA outputs into one df (unnlist the dfs)
IHA <- bind_rows(lst_stns_IHA, .id = "STATION_NUMBER")
View(IHA)

```

#Ice variables

Freeze date, freeze day of the year, and thaw date and thaw day of the year
-Group 1 and 2 functions use the longest consecutive runs of B dates, vs b_dates(), which just gets the raw values for the first and last B date.


```{r}

#This function calculates the freeze and thaw dates and their flow values, using the longest consecutive run of "B" Symbols
Group_1_ice_cover(df_ready)


#Function calculates the longest stretch of continuous ice coverage (Bs), per water year
Group_2_freeze_thaw(df_ready)
```


B dates - can use this as an alternative

This extracts the first b date, last b date, first b value, last b value, and the duration of the open water and ice effected seasons. Make sure there is a full, year-round dataset with minimal missing data. This just looks at the first and last B date, and disregards days where there may not be Bs 

```{r}

bdates <- b_dates(df_ready)

bdates

```


#Apply IHA to ow and ice-effected data
Annual - ice effected vars
(FYI the IHA library won't allow calculations with any NAs)

```{r, warning=FALSE}

#make sure no missing data in Values column

stns_daymonthyear <- ice_effected %>%
  mutate(Date = as.Date(Date)) %>%
  filter(waterYear > 1975) %>%
  filter(waterYear < 2021) %>%
  mutate(Date = format(Date,"%d-%m-%Y"))

lst_stns <- split(stns_daymonthyear, stns_daymonthyear$STATION_NUMBER )

lst_stns_IHA <- lapply(lst_stns, calc_IHA)

IHA <- bind_rows(lst_stns_IHA, .id = "STATION_NUMBER")

View(IHA)


#rm(IHA, stns_daymonthyear, lst_stns, lst_stns_IHA)
```

Annual - open water vars 
(FYI the IHA library won't allow calculations with any NAs)

```{r}

#make sure no missing data in Values column

stns_daymonthyear <- open_water %>%
  mutate(Date = as.Date(Date)) %>%
  filter(waterYear > 1975) %>%
  filter(waterYear < 2021) %>%
  mutate(Date = format(Date,"%d-%m-%Y"))

lst_stns <- split(stns_daymonthyear, stns_daymonthyear$STATION_NUMBER )

lst_stns_IHA <- lapply(lst_stns, calc_IHA)

IHA <- bind_rows(lst_stns_IHA, .id = "STATION_NUMBER")

View(IHA)

```


#Days of total ice effected data
```{r}

df_labeled %>%
  last date - first date +1 #total days ice effected data 

```


#Mann Kendall Trend Analysis
-Daniel wants this edited to use Zhang and Yue-Pilon methods in zyp package and then Kendall in Kendall package
-needs to be further scaled up, so that whole dataframes at a time can be run rather than variable by variable.  

Data preparation:
```{r}

#First expand dataframe to make sure there are all years present for all stations, even if there is no data- the Mann-Kendall function does not allow 

for (i in unique(IHA$STATION_NUMBER)) {
  min_yr <- min(IHA$Year)
  max_yr <- max(IHA$Year)
  IHA_expand <- IHA %>%
    mutate(Year = as.integer(Year)) %>%
    tidyr::complete(STATION_NUMBER, Year = min_yr:max_yr)
  return(IHA_expand)
}

#change any columns that begin with a number or have spaces, as the Mann-Kendall test doesn't like leading numbers or spaces in column headers
IHA_expand <- IHA_expand %>%
rename("One_Day_Max" = "1 Day Max",
           "One_Day_Min" = '1 Day Min',
           "Three_Day_Max" = "3 Day Max",
           "Three_Day_Min" = "3 Day Min",
           "Seven_Day_Min" ="7 Day Min",
          "Seven_Day_Max" = "7 Day Max",
          "Thirty_Day_Max" = "30 Day Max",
          "Thirty_Day_Min" = "30 Day Min",
          "Ninety_Day_Max" = "90 Day Max",
          "Ninety_Day_Min" = "90 Day Min",
          "High_pulse_number" = "High pulse number",
          "Low_pulse_number" = "Low pulse number",
          "High_pulse_length" = "High pulse length",
          "Low_pulse_length" = "Low pulse length")

```

Mann Kendall tests with alpha = .05. Only one variable at a time can be done, but multiple stations at a time are allowed

```{r, echo=FALSE, include = FALSE}

library(Kendall)
#Use calc_Mk to do a MK for all Stations for selected variables for IHA

Reversals <- calc_MK(IHA_expand, parameter = Reversals, start = 1961) %>%
  rename("Result_Reversals" = 'P_Value')

One_Day_Min <- calc_MK(IHA_expand, parameter = One_Day_Min , start = 1961) %>% rename("Result_One_Day_Min" = 'P_Value')

One_Day_Max <-  calc_MK(IHA_expand, parameter = One_Day_Max , start = 1961) %>% rename("Result_1_Day_Max" = 'P_Value')

Seven_Day_Min <- calc_MK(IHA_expand, parameter = Seven_Day_Min , start = 1961) %>% rename("Result_7_Day_Min" = 'P_Value')

Seven_Day_Max <-  calc_MK(IHA_expand, parameter = Seven_Day_Max , start = 1961) %>% rename("Result_7_Day_Max" = 'P_Value')

Thirty_Day_Min <- calc_MK(IHA_expand, parameter = Thirty_Day_Min , start = 1961) %>% rename("Result_30_Day_Min" = 'P_Value')

Thirty_Day_Max <-  calc_MK(IHA_expand, parameter = Thirty_Day_Max , start = 1961) %>% rename("Result_30_Day_Max" = 'P_Value')

High_pulse_number <-  calc_MK(IHA_expand, parameter = High_pulse_number , start = 1961) %>% rename("Result_High_pulse_number" = 'P_Value')

Low_pulse_number <-  calc_MK(IHA_expand, parameter = Low_pulse_number , start = 1961) %>% rename("Result_Low_pulse_number" = 'P_Value')

High_pulse_length <-  calc_MK(IHA_expand, parameter = High_pulse_length , start = 1961) %>% rename("Result_High_pulse_length" = 'P_Value')

Low_pulse_length <-  calc_MK(IHA_expand, parameter = Low_pulse_length , start = 1961) %>% rename("Result_Low_pulse_length" = 'P_Value')

#bind results together into one dataframe
result_MK_IHA <- cbind(Reversals, One_Day_Min, One_Day_Max, Seven_Day_Min, Seven_Day_Max, Thirty_Day_Min, Thirty_Day_Max, High_pulse_number, Low_pulse_number, High_pulse_length, Low_pulse_length )


```


```{r}

```

```{r}

```
